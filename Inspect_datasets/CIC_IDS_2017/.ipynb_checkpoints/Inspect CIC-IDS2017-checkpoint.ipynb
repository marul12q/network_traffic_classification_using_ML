{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8471d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier, KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB, ComplementNB, CategoricalNB\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.preprocessing import normalize, MinMaxScaler\n",
    "\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb280d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usefull fucntions\n",
    "def remove_nan_values(sample_array:np.array) -> np.array:\n",
    "    for sample_index, i in enumerate(sample_array):\n",
    "        for value_index, j in enumerate(i):\n",
    "            if np.isnan(j):\n",
    "               sample_array[sample_index][value_index] = 0.0\n",
    "    return sample_array\n",
    "\n",
    "def remove_1d_array_nan_values(sample_array: np.array, attack_categories: dict) -> np.array:\n",
    "    for value_index, j in enumerate(sample_array):\n",
    "        if j==' ':\n",
    "           sample_array[value_index] = 0.0\n",
    "        elif type(j) == str:\n",
    "            try:\n",
    "                sample_array[value_index] = int(j)\n",
    "            except:\n",
    "                sample_array[value_index] = attack_categories[j]\n",
    "        elif np.isnan(j):\n",
    "           sample_array[value_index] = 0.0\n",
    "    return sample_array\n",
    "\n",
    "def save_model(model, meta) -> None:\n",
    "    \"\"\"Function responsible for saving trained model. It must be called\n",
    "    after defining, training and predict.\n",
    "\n",
    "    :param: None\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    filename = f\"finalized_{meta}_{model}.sav\"\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "def load_model(filepath):\n",
    "    \"\"\"Function responsible for load model.\n",
    "\n",
    "    :param: None\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    return pickle.load(open(filepath, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedfa64c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d7af6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv',\n",
       " 'Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv',\n",
       " 'Wednesday-workingHours.pcap_ISCX.csv',\n",
       " 'Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv',\n",
       " 'Monday-WorkingHours.pcap_ISCX.csv',\n",
       " 'Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv',\n",
       " 'Tuesday-WorkingHours.pcap_ISCX.csv',\n",
       " 'Friday-WorkingHours-Morning.pcap_ISCX.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = '../../Datasets/CIC-IDS2017/MachineLearningCVE'\n",
    "os.listdir(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87ee0148",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [os.path.join(dataset_path,file) for file in os.listdir(dataset_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3585ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load multiple files\n",
    "li = []\n",
    "df = None\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c4fb3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {value: index for index, value in enumerate(list(frame[' Label'].unique()))}\n",
    "labels_binary = {value: 1 for index, value in enumerate(labels) if index!=0}\n",
    "labels_binary['BENIGN'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1be20b",
   "metadata": {},
   "source": [
    "## Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "850f3b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for classification\n",
    "chosen_features = list(frame.columns)[1:-1]\n",
    "\n",
    "x_data = frame[chosen_features].fillna(0.0)\n",
    "x_data = x_data.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "\n",
    "x_data = x_data.to_numpy()\n",
    "y_data = np.array([labels_binary[i] for i in frame[' Label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e8ec039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splt data to training and testing set\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x_data, y_data,\n",
    "                                                                    train_size=0.80,\n",
    "                                                                    test_size=0.20,\n",
    "                                                                    random_state=101)\n",
    "# remove nan values\n",
    "# x_train, x_test = remove_nan_values(x_train), remove_nan_values(x_test)\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')\n",
    "\n",
    "# normalization min max\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee73d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [GaussianNB(), \n",
    "          DecisionTreeClassifier(criterion=\"entropy\",\n",
    "                                 class_weight=\"balanced\",\n",
    "                                 random_state=10,\n",
    "                                 max_depth=20,\n",
    "                                 max_leaf_nodes=162,\n",
    "                                 min_samples_leaf=20,\n",
    "                                 min_impurity_decrease=0.00006,\n",
    "                                 min_samples_split=2),\n",
    "          RandomForestClassifier(criterion=\"entropy\",\n",
    "                                 class_weight=\"balanced\",\n",
    "                                 random_state=10,\n",
    "                                 max_depth=20,\n",
    "                                 max_leaf_nodes=162,\n",
    "                                 min_samples_leaf=20,\n",
    "                                 min_impurity_decrease=0.00006,\n",
    "                                 min_samples_split=2,\n",
    "                                 n_estimators=75),\n",
    "          MLPClassifier(hidden_layer_sizes=(15,30,60),\n",
    "                        solver=\"adam\",\n",
    "                        activation=\"relu\",\n",
    "                        learning_rate_init=0.002,\n",
    "                        learning_rate=\"adaptive\",\n",
    "                        max_iter=2000\n",
    "                       ),\n",
    "          AdaBoostClassifier(base_estimator=DecisionTreeClassifier(criterion='gini',\n",
    "                                                                   random_state=10,\n",
    "                                                                   class_weight='balanced',\n",
    "                                                                   max_depth=11,\n",
    "                                                                   max_leaf_nodes=162,\n",
    "                                                                   min_samples_leaf=20,\n",
    "                                                                   min_impurity_decrease=0.00006),\n",
    "                            n_estimators=3300,\n",
    "                            learning_rate=0.3,\n",
    "                            algorithm='SAMME.R'),\n",
    "         GradientBoostingClassifier(loss='deviance',\n",
    "                                   n_estimators=3200,\n",
    "                                   learning_rate=0.05)]\n",
    "\n",
    "\n",
    "models_mlp = [MLPClassifier(hidden_layer_sizes=(50,),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "             MLPClassifier(hidden_layer_sizes=(50,50),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(50,50,50),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(50,30,10),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               )\n",
    "             ]\n",
    "\n",
    "models_mlp2 = [\n",
    "             MLPClassifier(hidden_layer_sizes=(100,100),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(100,100,100),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(100,50,20),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               )\n",
    "             ]\n",
    "models_mlp3 = [\n",
    "             MLPClassifier(hidden_layer_sizes=(200,100, 50, 25),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(200,200,200),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(300,150,75),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               )\n",
    "             ]\n",
    "\n",
    "models_mlp_downsampling = [MLPClassifier(hidden_layer_sizes=(25,),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "             MLPClassifier(hidden_layer_sizes=(25,25),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(25,25,25),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(25,15,10),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "             MLPClassifier(hidden_layer_sizes=(15,),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(15,15),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(15,15,15),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "             MLPClassifier(hidden_layer_sizes=(30,15, 5),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(5,5,5),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               )\n",
    "             ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc17510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=20, max_leaf_nodes=162,\n",
      "                       min_impurity_decrease=6e-05, min_samples_leaf=20,\n",
      "                       random_state=10)\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=20, max_leaf_nodes=162,\n",
      "                       min_impurity_decrease=6e-05, min_samples_leaf=20,\n",
      "                       n_estimators=75, random_state=10)\n",
      "MLPClassifier(hidden_layer_sizes=(15, 30, 60), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n"
     ]
    }
   ],
   "source": [
    "# train models\n",
    "for model in models:\n",
    "    model.fit(x_train, y_train)\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2058c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b16621ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-06 10:31:58.389395: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-06 10:31:58.389422: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier, KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB, ComplementNB, CategoricalNB\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.preprocessing import normalize, LabelEncoder, MinMaxScaler\n",
    "\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, det_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense, Activation, GRU\n",
    "from sklearn.preprocessing import normalize, LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a5d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usefull fucntions\n",
    "def remove_nan_values(sample_array:np.array) -> np.array:\n",
    "    for sample_index, i in enumerate(sample_array):\n",
    "        for value_index, j in enumerate(i):\n",
    "            if j==' ':\n",
    "               sample_array[sample_index][value_index] = 0.0\n",
    "            elif type(j) == str:\n",
    "                sample_array[sample_index][value_index] = int(j)\n",
    "            elif np.isnan(j):\n",
    "               sample_array[sample_index][value_index] = 0.0\n",
    "    return sample_array\n",
    "\n",
    "def remove_1d_array_nan_values(sample_array: np.array, attack_categories: dict) -> np.array:\n",
    "    for value_index, j in enumerate(sample_array):\n",
    "        if j==' ':\n",
    "           sample_array[value_index] = 0.0\n",
    "        elif type(j) == str:\n",
    "            try:\n",
    "                sample_array[value_index] = int(j)\n",
    "            except:\n",
    "                sample_array[value_index] = attack_categories[j]\n",
    "        elif np.isnan(j):\n",
    "           sample_array[value_index] = 0.0\n",
    "    return sample_array\n",
    "\n",
    "def save_model(model, name, prefix) -> None:\n",
    "    \"\"\"Function responsible for saving trained model. It must be called\n",
    "    after defining, training and predict.\n",
    "\n",
    "    :param: None\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    filename = f\"{name}_{prefix}.sav\"\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "def load_model(filepath):\n",
    "    \"\"\"Function responsible for load model.\n",
    "\n",
    "    :param: None\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    return pickle.load(open(filepath, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adf96ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data to pandas DataFrame\n",
    "df_path = '/home/mkubita/Pulpit/Praca Magisterska/Zbiory danych/TON_IoT/Train_Test_datasets/Train_Test_Network_dataset/Train_Test_Network.csv'\n",
    "df = pd.read_csv(df_path, index_col=None, header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "badb016d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161043"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label'] == 1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02c0f364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.grid()\n",
    "plt.title(\"Rozkład kategorii etykiet\")\n",
    "plt.pie([df[df['label'] == 0].shape[0], df[df['label'] == 1].shape[0]],\n",
    "       labels=['Ruch Normalny', 'Anomalia'], autopct='%1.1f%%', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee3f6610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.grid()\n",
    "plt.title(\"Rozkład kategorii klas\")\n",
    "plt.hist(df['type'].sort_values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e014d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(df.columns)\n",
    "\n",
    "for i in ['src_ip', 'src_port', 'dst_ip', 'dst_port', 'label', 'type']:\n",
    "    features.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54d8d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical features\n",
    "cat_features = ['conn_state', 'proto', 'service', 'dns_query', 'ssl_version', 'ssl_cipher', 'ssl_subject', 'ssl_issuer', 'http_method', 'http_uri', 'http_version', 'http_orig_mime_types', 'http_resp_mime_types', 'weird_name', 'weird_addl', 'weird_notice', 'http_user_agent', 'dns_rcode','dns_AA', 'dns_RD', 'dns_RA', 'dns_rejected', 'ssl_established', 'ssl_resumed', 'http_trans_depth']\n",
    "for i in cat_features:\n",
    "    encoder = LabelEncoder()\n",
    "    df[i] = encoder.fit_transform(df[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18840fa3",
   "metadata": {},
   "source": [
    "### Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf7b3ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for classification\n",
    "df = df.dropna()\n",
    "\n",
    "x = df[features].to_numpy()\n",
    "y = df['label'].to_numpy()\n",
    "\n",
    "# normalization min max\n",
    "scaler = MinMaxScaler()\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff6fff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y,\n",
    "                                                                    train_size=0.80,\n",
    "                                                                    test_size=0.20,\n",
    "                                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a60aafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [GaussianNB(), \n",
    "          DecisionTreeClassifier(criterion=\"entropy\",\n",
    "                                 class_weight=\"balanced\",\n",
    "                                 random_state=10,\n",
    "                                 max_depth=20,\n",
    "                                 max_leaf_nodes=162,\n",
    "                                 min_samples_leaf=20,\n",
    "                                 min_impurity_decrease=0.00006,\n",
    "                                 min_samples_split=2),\n",
    "          RandomForestClassifier(criterion=\"entropy\",\n",
    "                                 class_weight=\"balanced\",\n",
    "                                 random_state=10,\n",
    "                                 max_depth=20,\n",
    "                                 max_leaf_nodes=162,\n",
    "                                 min_samples_leaf=20,\n",
    "                                 min_impurity_decrease=0.00006,\n",
    "                                 min_samples_split=2,\n",
    "                                 n_estimators=75),\n",
    "          MLPClassifier(hidden_layer_sizes=(15,30,60),\n",
    "                        solver=\"adam\",\n",
    "                        activation=\"relu\",\n",
    "                        learning_rate_init=0.002,\n",
    "                        learning_rate=\"adaptive\",\n",
    "                        max_iter=2000\n",
    "                       ),\n",
    "          AdaBoostClassifier(base_estimator=DecisionTreeClassifier(criterion='gini',\n",
    "                                                                   random_state=10,\n",
    "                                                                   class_weight='balanced',\n",
    "                                                                   max_depth=11,\n",
    "                                                                   max_leaf_nodes=162,\n",
    "                                                                   min_samples_leaf=20,\n",
    "                                                                   min_impurity_decrease=0.00006),\n",
    "                            n_estimators=3300,\n",
    "                            learning_rate=0.3,\n",
    "                            algorithm='SAMME.R'),\n",
    "         GradientBoostingClassifier(loss='deviance',\n",
    "                                   n_estimators=3200,\n",
    "                                   learning_rate=0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8285bc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_mlp = [MLPClassifier(hidden_layer_sizes=(50,),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "             MLPClassifier(hidden_layer_sizes=(50,50),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(50,50,50),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(50,30,10),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "             MLPClassifier(hidden_layer_sizes=(100,100),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(100,100,100),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(100,50,20),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "             MLPClassifier(hidden_layer_sizes=(200,100, 50, 25),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(200,200,200),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(300,150,75),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               )\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2d8a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_mlp_downsampling = [MLPClassifier(hidden_layer_sizes=(25,),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "             MLPClassifier(hidden_layer_sizes=(25,25),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(25,25,25),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(25,15,10),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "             MLPClassifier(hidden_layer_sizes=(15,),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(15,15),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(15,15,15),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "             MLPClassifier(hidden_layer_sizes=(30,15, 5),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(5,5,5),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               )\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b4bb6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(hidden_layer_sizes=(25,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(25, 25), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(25, 25, 25), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(25, 15, 10), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(15,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(15, 15), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(15, 15, 15), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(30, 15, 5), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(5, 5, 5), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n"
     ]
    }
   ],
   "source": [
    "for model in models_mlp_downsampling:\n",
    "    model.fit(x_train, y_train)\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8554fb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(hidden_layer_sizes=(50,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(50, 50), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(50, 50, 50), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(50, 30, 10), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(100, 100), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(100, 100, 100), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(100, 50, 20), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(200, 100, 50, 25), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(200, 200, 200), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(300, 150, 75), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n"
     ]
    }
   ],
   "source": [
    "# train models\n",
    "for model in models_mlp:\n",
    "    model.fit(x_train, y_train)\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1bd238bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=20, max_leaf_nodes=162,\n",
      "                       min_impurity_decrease=6e-05, min_samples_leaf=20,\n",
      "                       random_state=10)\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=20, max_leaf_nodes=162,\n",
      "                       min_impurity_decrease=6e-05, min_samples_leaf=20,\n",
      "                       n_estimators=75, random_state=10)\n",
      "MLPClassifier(hidden_layer_sizes=(15, 30, 60), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced',\n",
      "                                                         max_depth=11,\n",
      "                                                         max_leaf_nodes=162,\n",
      "                                                         min_impurity_decrease=6e-05,\n",
      "                                                         min_samples_leaf=20,\n",
      "                                                         random_state=10),\n",
      "                   learning_rate=0.3, n_estimators=3300)\n",
      "GradientBoostingClassifier(learning_rate=0.05, n_estimators=3200)\n"
     ]
    }
   ],
   "source": [
    "# train models\n",
    "for model in models:\n",
    "    model.fit(x_train, y_train)\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "18625ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(368834, 39)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5146ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {i: None for i in models_mlp_downsampling}\n",
    "for model, model_str in zip(models_mlp_downsampling, predictions):\n",
    "    predictions[model_str] = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "76398d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy [%]</th>\n",
       "      <th>Precision [%]</th>\n",
       "      <th>Recall [%]</th>\n",
       "      <th>F1_score [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>72.8</td>\n",
       "      <td>56.2</td>\n",
       "      <td>99.6</td>\n",
       "      <td>71.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>98.0</td>\n",
       "      <td>94.6</td>\n",
       "      <td>99.9</td>\n",
       "      <td>97.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultiLayerPercepton</td>\n",
       "      <td>97.3</td>\n",
       "      <td>93.4</td>\n",
       "      <td>99.4</td>\n",
       "      <td>96.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy [%]  Precision [%]  Recall [%]  F1_score [%]\n",
       "0           NaiveBayes          72.8           56.2        99.6          71.8\n",
       "1         DecisionTree         100.0           99.9       100.0          99.9\n",
       "2         RandomForest          98.0           94.6        99.9          97.2\n",
       "3  MultiLayerPercepton          97.3           93.4        99.4          96.3\n",
       "4             AdaBoost         100.0          100.0       100.0         100.0\n",
       "5        GradientBoost         100.0          100.0       100.0         100.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "# fpr_list = []\n",
    "for model, model_str in zip(models, predictions):\n",
    "    accuracy = accuracy_score(y_test, predictions[model_str])\n",
    "    precision = precision_score(y_test, predictions[model_str], average='binary')\n",
    "    recall = recall_score(y_test, predictions[model_str], average='binary')\n",
    "    f1_ = f1_score(y_test, predictions[model_str], average='binary')\n",
    "#     fpr_score = det_curve(y_test, predictions[model_str])[0][1]\n",
    "    \n",
    "    accuracy_list.append(round(accuracy, 3) * 100)\n",
    "    precision_list.append(round(precision,3) * 100)\n",
    "    recall_list.append(round(recall,3) * 100)\n",
    "#     fpr_list.append(round(fpr_score, 3) * 100)\n",
    "    f1_list.append(round(f1_,3) * 100)\n",
    "\n",
    "# accuracy_list[3] = 83.9\n",
    "# precision_list[3] = 82.4\n",
    "\n",
    "# accuracy_list.append(86.6)\n",
    "# accuracy_list.append(86.6)\n",
    "# precision_list.append(81.3)\n",
    "# recall_list.append(98.5)\n",
    "# f1_list.append(89.1)\n",
    "# precision_list.append(78.2)\n",
    "# recall_list.append(99.2)\n",
    "# f1_list.append(87.5)\n",
    "\n",
    "results = {'Model': ['NaiveBayes', 'DecisionTree', 'RandomForest', 'MultiLayerPercepton', 'AdaBoost', 'GradientBoost'],\n",
    "           'Accuracy [%]': accuracy_list,\n",
    "           'Precision [%]': precision_list,\n",
    "           'Recall [%]': recall_list,\n",
    "           'F1_score [%]': f1_list,\n",
    "#            'FPR_score [%]': fpr_list\n",
    "          }\n",
    " \n",
    "# Convert the dictionary into DataFrame \n",
    "result_metrics = pd.DataFrame(results)\n",
    "result_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5c4225a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy [%]</th>\n",
       "      <th>Precision [%]</th>\n",
       "      <th>Recall [%]</th>\n",
       "      <th>F1_score [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(50,), learni...</td>\n",
       "      <td>97.2</td>\n",
       "      <td>93.4</td>\n",
       "      <td>98.9</td>\n",
       "      <td>96.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(50, 50), lea...</td>\n",
       "      <td>97.1</td>\n",
       "      <td>92.7</td>\n",
       "      <td>99.4</td>\n",
       "      <td>95.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(50, 50, 50),...</td>\n",
       "      <td>97.6</td>\n",
       "      <td>94.0</td>\n",
       "      <td>99.5</td>\n",
       "      <td>96.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(50, 30, 10),...</td>\n",
       "      <td>97.4</td>\n",
       "      <td>93.3</td>\n",
       "      <td>99.5</td>\n",
       "      <td>96.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(100, 100), l...</td>\n",
       "      <td>95.4</td>\n",
       "      <td>96.9</td>\n",
       "      <td>89.7</td>\n",
       "      <td>93.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(100, 100, 10...</td>\n",
       "      <td>97.6</td>\n",
       "      <td>94.1</td>\n",
       "      <td>99.4</td>\n",
       "      <td>96.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(100, 50, 20)...</td>\n",
       "      <td>97.1</td>\n",
       "      <td>92.7</td>\n",
       "      <td>99.5</td>\n",
       "      <td>95.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(200, 100, 50...</td>\n",
       "      <td>97.3</td>\n",
       "      <td>93.5</td>\n",
       "      <td>99.2</td>\n",
       "      <td>96.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(200, 200, 20...</td>\n",
       "      <td>97.3</td>\n",
       "      <td>93.4</td>\n",
       "      <td>99.4</td>\n",
       "      <td>96.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(300, 150, 75...</td>\n",
       "      <td>96.8</td>\n",
       "      <td>92.2</td>\n",
       "      <td>99.3</td>\n",
       "      <td>95.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  Accuracy [%]  \\\n",
       "0  MLPClassifier(hidden_layer_sizes=(50,), learni...          97.2   \n",
       "1  MLPClassifier(hidden_layer_sizes=(50, 50), lea...          97.1   \n",
       "2  MLPClassifier(hidden_layer_sizes=(50, 50, 50),...          97.6   \n",
       "3  MLPClassifier(hidden_layer_sizes=(50, 30, 10),...          97.4   \n",
       "4  MLPClassifier(hidden_layer_sizes=(100, 100), l...          95.4   \n",
       "5  MLPClassifier(hidden_layer_sizes=(100, 100, 10...          97.6   \n",
       "6  MLPClassifier(hidden_layer_sizes=(100, 50, 20)...          97.1   \n",
       "7  MLPClassifier(hidden_layer_sizes=(200, 100, 50...          97.3   \n",
       "8  MLPClassifier(hidden_layer_sizes=(200, 200, 20...          97.3   \n",
       "9  MLPClassifier(hidden_layer_sizes=(300, 150, 75...          96.8   \n",
       "\n",
       "   Precision [%]  Recall [%]  F1_score [%]  \n",
       "0           93.4        98.9          96.1  \n",
       "1           92.7        99.4          95.9  \n",
       "2           94.0        99.5          96.7  \n",
       "3           93.3        99.5          96.3  \n",
       "4           96.9        89.7          93.2  \n",
       "5           94.1        99.4          96.7  \n",
       "6           92.7        99.5          95.9  \n",
       "7           93.5        99.2          96.2  \n",
       "8           93.4        99.4          96.3  \n",
       "9           92.2        99.3          95.6  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "# fpr_list = []\n",
    "for model, model_str in zip(models_mlp, predictions):\n",
    "    accuracy = accuracy_score(y_test, predictions[model_str])\n",
    "    precision = precision_score(y_test, predictions[model_str], average='binary')\n",
    "    recall = recall_score(y_test, predictions[model_str], average='binary')\n",
    "    f1_ = f1_score(y_test, predictions[model_str], average='binary')\n",
    "#     fpr_score = det_curve(y_test, predictions[model_str])[0][1]\n",
    "    \n",
    "    accuracy_list.append(round(accuracy, 3) * 100)\n",
    "    precision_list.append(round(precision,3) * 100)\n",
    "    recall_list.append(round(recall,3) * 100)\n",
    "#     fpr_list.append(round(fpr_score, 3) * 100)\n",
    "    f1_list.append(round(f1_,3) * 100)\n",
    "\n",
    "# accuracy_list[3] = 83.9\n",
    "# precision_list[3] = 82.4\n",
    "\n",
    "# accuracy_list.append(86.6)\n",
    "# accuracy_list.append(86.6)\n",
    "# precision_list.append(81.3)\n",
    "# recall_list.append(98.5)\n",
    "# f1_list.append(89.1)\n",
    "# precision_list.append(78.2)\n",
    "# recall_list.append(99.2)\n",
    "# f1_list.append(87.5)\n",
    "\n",
    "results = {'Model': models_mlp,\n",
    "           'Accuracy [%]': accuracy_list,\n",
    "           'Precision [%]': precision_list,\n",
    "           'Recall [%]': recall_list,\n",
    "           'F1_score [%]': f1_list,\n",
    "#            'FPR_score [%]': fpr_list\n",
    "          }\n",
    " \n",
    "# Convert the dictionary into DataFrame \n",
    "result_metrics = pd.DataFrame(results)\n",
    "result_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5054257e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy [%]</th>\n",
       "      <th>Precision [%]</th>\n",
       "      <th>Recall [%]</th>\n",
       "      <th>F1_score [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(25,), learni...</td>\n",
       "      <td>96.8</td>\n",
       "      <td>93.3</td>\n",
       "      <td>97.9</td>\n",
       "      <td>95.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(25, 25), lea...</td>\n",
       "      <td>97.2</td>\n",
       "      <td>93.3</td>\n",
       "      <td>99.2</td>\n",
       "      <td>96.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(25, 25, 25),...</td>\n",
       "      <td>97.3</td>\n",
       "      <td>93.2</td>\n",
       "      <td>99.4</td>\n",
       "      <td>96.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(25, 15, 10),...</td>\n",
       "      <td>97.1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>95.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(15,), learni...</td>\n",
       "      <td>96.8</td>\n",
       "      <td>92.4</td>\n",
       "      <td>99.0</td>\n",
       "      <td>95.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(15, 15), lea...</td>\n",
       "      <td>97.4</td>\n",
       "      <td>93.5</td>\n",
       "      <td>99.3</td>\n",
       "      <td>96.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(15, 15, 15),...</td>\n",
       "      <td>97.6</td>\n",
       "      <td>94.4</td>\n",
       "      <td>99.1</td>\n",
       "      <td>96.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(30, 15, 5), ...</td>\n",
       "      <td>97.1</td>\n",
       "      <td>93.1</td>\n",
       "      <td>98.9</td>\n",
       "      <td>95.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(5, 5, 5), le...</td>\n",
       "      <td>96.4</td>\n",
       "      <td>91.9</td>\n",
       "      <td>98.4</td>\n",
       "      <td>95.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  Accuracy [%]  \\\n",
       "0  MLPClassifier(hidden_layer_sizes=(25,), learni...          96.8   \n",
       "1  MLPClassifier(hidden_layer_sizes=(25, 25), lea...          97.2   \n",
       "2  MLPClassifier(hidden_layer_sizes=(25, 25, 25),...          97.3   \n",
       "3  MLPClassifier(hidden_layer_sizes=(25, 15, 10),...          97.1   \n",
       "4  MLPClassifier(hidden_layer_sizes=(15,), learni...          96.8   \n",
       "5  MLPClassifier(hidden_layer_sizes=(15, 15), lea...          97.4   \n",
       "6  MLPClassifier(hidden_layer_sizes=(15, 15, 15),...          97.6   \n",
       "7  MLPClassifier(hidden_layer_sizes=(30, 15, 5), ...          97.1   \n",
       "8  MLPClassifier(hidden_layer_sizes=(5, 5, 5), le...          96.4   \n",
       "\n",
       "   Precision [%]  Recall [%]  F1_score [%]  \n",
       "0           93.3        97.9          95.5  \n",
       "1           93.3        99.2          96.2  \n",
       "2           93.2        99.4          96.2  \n",
       "3           93.0        99.0          95.9  \n",
       "4           92.4        99.0          95.6  \n",
       "5           93.5        99.3          96.3  \n",
       "6           94.4        99.1          96.7  \n",
       "7           93.1        98.9          95.9  \n",
       "8           91.9        98.4          95.1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "# fpr_list = []\n",
    "for model, model_str in zip(models_mlp_downsampling, predictions):\n",
    "    accuracy = accuracy_score(y_test, predictions[model_str])\n",
    "    precision = precision_score(y_test, predictions[model_str], average='binary')\n",
    "    recall = recall_score(y_test, predictions[model_str], average='binary')\n",
    "    f1_ = f1_score(y_test, predictions[model_str], average='binary')\n",
    "    \n",
    "    accuracy_list.append(round(accuracy, 3) * 100)\n",
    "    precision_list.append(round(precision,3) * 100)\n",
    "    recall_list.append(round(recall,3) * 100)\n",
    "    f1_list.append(round(f1_,3) * 100)\n",
    "\n",
    "\n",
    "results = {'Model': models_mlp_downsampling,\n",
    "           'Accuracy [%]': accuracy_list,\n",
    "           'Precision [%]': precision_list,\n",
    "           'Recall [%]': recall_list,\n",
    "           'F1_score [%]': f1_list,\n",
    "#            'FPR_score [%]': fpr_list\n",
    "          }\n",
    " \n",
    "# Convert the dictionary into DataFrame \n",
    "result_metrics = pd.DataFrame(results)\n",
    "result_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cd74fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {i: None for i in models_mlp}\n",
    "for model, model_str in zip(models_mlp, predictions):\n",
    "    predictions[model_str] = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e45af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzic architektury MLP z mniejsza iloscia parametrów (downsampling)\n",
    "\n",
    "# AdaBoost, GBT -> testy\n",
    "\n",
    "# Inne zbiory danych\n",
    "\n",
    "\n",
    "# wazny element pracy -> dobrze opisany zbior danych\n",
    "# za tydzien piatek 11:30 24.06\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83fc568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0552466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 00:02:46.669755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-07 00:02:46.670311: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-07 00:02:46.670415: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-07 00:02:46.670498: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-07 00:02:46.695391: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-07 00:02:46.695731: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-07 00:02:46.695913: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-06-07 00:02:46.695950: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-06-07 00:02:46.697435: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(300, activation=\"tanh\", return_sequences = True, input_shape = (39, 1)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(LSTM(200, activation=\"tanh\", return_sequences = True))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(LSTM(100, activation=\"tanh\", return_sequences = True))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(LSTM(80, activation=\"tanh\"))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b0e30ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5764/5764 [==============================] - 1059s 183ms/step - loss: 0.4214 - accuracy: 0.7530 - val_loss: 0.4253 - val_accuracy: 0.7012\n",
      "Epoch 2/20\n",
      "5764/5764 [==============================] - 1034s 179ms/step - loss: 0.3672 - accuracy: 0.8082 - val_loss: 0.5352 - val_accuracy: 0.6518\n",
      "Epoch 3/20\n",
      "5764/5764 [==============================] - 1085s 188ms/step - loss: 0.3649 - accuracy: 0.8029 - val_loss: 0.4680 - val_accuracy: 0.6724\n",
      "Epoch 4/20\n",
      "5764/5764 [==============================] - 1127s 196ms/step - loss: 0.2619 - accuracy: 0.8824 - val_loss: 0.1809 - val_accuracy: 0.9201\n",
      "Epoch 5/20\n",
      "5764/5764 [==============================] - 1195s 207ms/step - loss: 0.2678 - accuracy: 0.8700 - val_loss: 0.2246 - val_accuracy: 0.8881\n",
      "Epoch 6/20\n",
      "5764/5764 [==============================] - 1217s 211ms/step - loss: 0.2341 - accuracy: 0.8869 - val_loss: 0.1487 - val_accuracy: 0.9583\n",
      "Epoch 7/20\n",
      "5764/5764 [==============================] - 1219s 211ms/step - loss: 0.2149 - accuracy: 0.9064 - val_loss: 0.1800 - val_accuracy: 0.9106\n",
      "Epoch 8/20\n",
      "5764/5764 [==============================] - 1221s 212ms/step - loss: 0.1555 - accuracy: 0.9351 - val_loss: 0.1595 - val_accuracy: 0.9455\n",
      "Epoch 9/20\n",
      "5764/5764 [==============================] - 1222s 212ms/step - loss: 0.2285 - accuracy: 0.9016 - val_loss: 0.2694 - val_accuracy: 0.8701\n",
      "Epoch 10/20\n",
      "5764/5764 [==============================] - 1222s 212ms/step - loss: 0.2248 - accuracy: 0.8952 - val_loss: 0.1270 - val_accuracy: 0.9601\n",
      "Epoch 11/20\n",
      "5764/5764 [==============================] - 1224s 212ms/step - loss: 0.1978 - accuracy: 0.9057 - val_loss: 0.1567 - val_accuracy: 0.9339\n",
      "Epoch 12/20\n",
      "5764/5764 [==============================] - 1225s 213ms/step - loss: 0.2544 - accuracy: 0.8780 - val_loss: 0.2121 - val_accuracy: 0.8836\n",
      "Epoch 13/20\n",
      "5764/5764 [==============================] - 1227s 213ms/step - loss: 0.1746 - accuracy: 0.9307 - val_loss: 0.3007 - val_accuracy: 0.8451\n",
      "Epoch 14/20\n",
      "5764/5764 [==============================] - 1228s 213ms/step - loss: 0.1964 - accuracy: 0.9126 - val_loss: 0.1413 - val_accuracy: 0.9277\n",
      "Epoch 15/20\n",
      "5764/5764 [==============================] - 1222s 212ms/step - loss: 0.1509 - accuracy: 0.9388 - val_loss: 0.1360 - val_accuracy: 0.9464\n",
      "Epoch 16/20\n",
      "5764/5764 [==============================] - 1226s 213ms/step - loss: 0.2053 - accuracy: 0.9108 - val_loss: 0.1466 - val_accuracy: 0.9586\n",
      "Epoch 17/20\n",
      "5764/5764 [==============================] - 1229s 213ms/step - loss: 0.1790 - accuracy: 0.9255 - val_loss: 0.1747 - val_accuracy: 0.9110\n",
      "Epoch 18/20\n",
      "5764/5764 [==============================] - 1228s 213ms/step - loss: 0.1899 - accuracy: 0.9172 - val_loss: 0.2822 - val_accuracy: 0.8958\n",
      "Epoch 19/20\n",
      "5764/5764 [==============================] - 1230s 213ms/step - loss: 0.1601 - accuracy: 0.9372 - val_loss: 0.3011 - val_accuracy: 0.8736\n",
      "Epoch 20/20\n",
      "5764/5764 [==============================] - 1230s 213ms/step - loss: 0.1506 - accuracy: 0.9394 - val_loss: 0.0878 - val_accuracy: 0.9643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9dd90d3550>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, \n",
    "          epochs=20, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1d86edfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.964331030593543 0.9276747291883068 0.9734662099034569 0.9500189955170579\n"
     ]
    }
   ],
   "source": [
    "prediction_lstm = model.predict(x_test)\n",
    "prediction_lstm = prediction_lstm.flatten()\n",
    "prediction_lstm = [int(round(i,0)) for i in prediction_lstm]\n",
    "\n",
    "accuracy = accuracy_score(y_test, prediction_lstm)\n",
    "precision = precision_score(y_test, prediction_lstm, average='binary')\n",
    "recall = recall_score(y_test, prediction_lstm, average='binary')\n",
    "f1_ = f1_score(y_test, prediction_lstm, average='binary')\n",
    "\n",
    "print(accuracy, precision, recall, f1_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a021f00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 09:22:27.441232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-07 09:22:27.441581: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-07 09:22:27.441644: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-07 09:22:27.441699: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-07 09:22:27.468290: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-07 09:22:27.468545: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-07 09:22:27.468780: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-06-07 09:22:27.468810: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-06-07 09:22:27.470300: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model_GRU = Sequential()\n",
    "\n",
    "model_GRU.add(GRU(300, activation=\"tanh\", return_sequences = True, input_shape = (39, 1)))\n",
    "model_GRU.add(Dropout(0.4))\n",
    "\n",
    "model_GRU.add(GRU(200, activation=\"tanh\", return_sequences = True))\n",
    "model_GRU.add(Dropout(0.4))\n",
    "\n",
    "model_GRU.add(GRU(100, activation=\"tanh\", return_sequences = True))\n",
    "model_GRU.add(Dropout(0.4))\n",
    "\n",
    "model_GRU.add(GRU(80, activation=\"tanh\"))\n",
    "model_GRU.add(Dropout(0.4))\n",
    "\n",
    "model_GRU.add(Dense(1))\n",
    "model_GRU.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model_GRU.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b716ce8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5764/5764 [==============================] - 1009s 174ms/step - loss: 0.2773 - accuracy: 0.8680 - val_loss: 0.2482 - val_accuracy: 0.8810\n",
      "Epoch 2/20\n",
      "5764/5764 [==============================] - 1070s 186ms/step - loss: 0.1640 - accuracy: 0.9324 - val_loss: 0.1240 - val_accuracy: 0.9491\n",
      "Epoch 3/20\n",
      "5764/5764 [==============================] - 1022s 177ms/step - loss: 0.1224 - accuracy: 0.9532 - val_loss: 0.3028 - val_accuracy: 0.8785\n",
      "Epoch 4/20\n",
      "5764/5764 [==============================] - 1104s 192ms/step - loss: 0.1829 - accuracy: 0.9287 - val_loss: 0.1325 - val_accuracy: 0.9567\n",
      "Epoch 5/20\n",
      "5764/5764 [==============================] - 1098s 190ms/step - loss: 0.1669 - accuracy: 0.9346 - val_loss: 0.1297 - val_accuracy: 0.9444\n",
      "Epoch 6/20\n",
      "5764/5764 [==============================] - 1115s 194ms/step - loss: 0.1689 - accuracy: 0.9318 - val_loss: 0.1907 - val_accuracy: 0.8768\n",
      "Epoch 7/20\n",
      "5764/5764 [==============================] - 1119s 194ms/step - loss: 0.1453 - accuracy: 0.9452 - val_loss: 0.1332 - val_accuracy: 0.9560\n",
      "Epoch 8/20\n",
      "5764/5764 [==============================] - 1140s 198ms/step - loss: 0.1534 - accuracy: 0.9409 - val_loss: 0.1177 - val_accuracy: 0.9585\n",
      "Epoch 9/20\n",
      "5764/5764 [==============================] - 1120s 194ms/step - loss: 0.1541 - accuracy: 0.9397 - val_loss: 0.1478 - val_accuracy: 0.9260\n",
      "Epoch 10/20\n",
      "5764/5764 [==============================] - 1101s 191ms/step - loss: 0.1509 - accuracy: 0.9425 - val_loss: 0.1217 - val_accuracy: 0.9592\n",
      "Epoch 11/20\n",
      "5764/5764 [==============================] - 1065s 185ms/step - loss: 0.1325 - accuracy: 0.9505 - val_loss: 0.1262 - val_accuracy: 0.9576\n",
      "Epoch 12/20\n",
      "5764/5764 [==============================] - 1154s 200ms/step - loss: 0.1500 - accuracy: 0.9435 - val_loss: 0.1280 - val_accuracy: 0.9615\n",
      "Epoch 13/20\n",
      "5764/5764 [==============================] - 1167s 202ms/step - loss: 0.1410 - accuracy: 0.9473 - val_loss: 0.1133 - val_accuracy: 0.9613\n",
      "Epoch 14/20\n",
      "5764/5764 [==============================] - 1164s 202ms/step - loss: 0.1407 - accuracy: 0.9470 - val_loss: 0.1054 - val_accuracy: 0.9604\n",
      "Epoch 15/20\n",
      "5764/5764 [==============================] - 1160s 201ms/step - loss: 0.1451 - accuracy: 0.9460 - val_loss: 0.1303 - val_accuracy: 0.9570\n",
      "Epoch 16/20\n",
      "5764/5764 [==============================] - 1056s 183ms/step - loss: 0.1762 - accuracy: 0.9278 - val_loss: 0.1455 - val_accuracy: 0.9641\n",
      "Epoch 17/20\n",
      "5764/5764 [==============================] - 1113s 193ms/step - loss: 0.1376 - accuracy: 0.9481 - val_loss: 0.1120 - val_accuracy: 0.9625\n",
      "Epoch 18/20\n",
      "5764/5764 [==============================] - 1099s 191ms/step - loss: 0.1452 - accuracy: 0.9473 - val_loss: 0.1220 - val_accuracy: 0.9601\n",
      "Epoch 19/20\n",
      "5764/5764 [==============================] - 1138s 197ms/step - loss: 0.2115 - accuracy: 0.9138 - val_loss: 0.2085 - val_accuracy: 0.9208\n",
      "Epoch 20/20\n",
      "5764/5764 [==============================] - 1146s 199ms/step - loss: 0.1809 - accuracy: 0.9264 - val_loss: 0.2169 - val_accuracy: 0.9238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd96e1948e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_GRU.fit(x_train, y_train, batch_size=64, \n",
    "          epochs=20, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02174530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9238469129911397 0.8411105672485996 0.9632824665213329 0.8980605075198885\n"
     ]
    }
   ],
   "source": [
    "prediction_gru = model_GRU.predict(x_test)\n",
    "prediction_gru = prediction_gru.flatten()\n",
    "prediction_gru = [int(round(i,0)) for i in prediction_gru]\n",
    "\n",
    "accuracy = accuracy_score(y_test, prediction_gru)\n",
    "precision = precision_score(y_test, prediction_gru, average='binary')\n",
    "recall = recall_score(y_test, prediction_gru, average='binary')\n",
    "f1_ = f1_score(y_test, prediction_gru, average='binary')\n",
    "\n",
    "print(accuracy, precision, recall, f1_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b585d560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f262cfe4",
   "metadata": {},
   "source": [
    "## Reduced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "991d190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_features = ['ts', 'proto', 'src_ip_bytes', 'src_pkts', 'dst_ip_bytes', 'dst_pkts', 'conn_state', 'dst_bytes', 'src_bytes', 'duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2106654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for classification\n",
    "\n",
    "x_reduced = df[features][reduced_features].to_numpy()\n",
    "y_reduced = df['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a25e12db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization min max\n",
    "scaler = MinMaxScaler()\n",
    "x_reduced = scaler.fit_transform(x_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a36e043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "x_reduced_train, x_reduced_test, y_reduced_train, y_reduced_test = model_selection.train_test_split(x_reduced, y_reduced,\n",
    "                                                                    train_size=0.80,\n",
    "                                                                    test_size=0.20,\n",
    "                                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07fc2b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_reduced = [GaussianNB(), \n",
    "          DecisionTreeClassifier(criterion=\"entropy\",\n",
    "                                 class_weight=\"balanced\",\n",
    "                                 random_state=10,\n",
    "                                 max_depth=20,\n",
    "                                 max_leaf_nodes=162,\n",
    "                                 min_samples_leaf=20,\n",
    "                                 min_impurity_decrease=0.00006,\n",
    "                                 min_samples_split=2),\n",
    "          RandomForestClassifier(criterion=\"entropy\",\n",
    "                                 class_weight=\"balanced\",\n",
    "                                 random_state=10,\n",
    "                                 max_depth=20,\n",
    "                                 max_leaf_nodes=162,\n",
    "                                 min_samples_leaf=20,\n",
    "                                 min_impurity_decrease=0.00006,\n",
    "                                 min_samples_split=2,\n",
    "                                 n_estimators=75),\n",
    "          MLPClassifier(hidden_layer_sizes=(15,30,60),\n",
    "                        solver=\"adam\",\n",
    "                        activation=\"relu\",\n",
    "                        learning_rate_init=0.002,\n",
    "                        learning_rate=\"adaptive\",\n",
    "                        max_iter=2000\n",
    "                       ),\n",
    "          AdaBoostClassifier(base_estimator=DecisionTreeClassifier(criterion='gini',\n",
    "                                                                   random_state=10,\n",
    "                                                                   class_weight='balanced',\n",
    "                                                                   max_depth=11,\n",
    "                                                                   max_leaf_nodes=162,\n",
    "                                                                   min_samples_leaf=20,\n",
    "                                                                   min_impurity_decrease=0.00006),\n",
    "                            n_estimators=3300,\n",
    "                            learning_rate=0.3,\n",
    "                            algorithm='SAMME.R'),\n",
    "         GradientBoostingClassifier(loss='deviance',\n",
    "                                   n_estimators=3200,\n",
    "                                   learning_rate=0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faacf61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_mlp = [MLPClassifier(hidden_layer_sizes=(50,),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "             MLPClassifier(hidden_layer_sizes=(50,50),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(50,50,50),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(50,30,10),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "             MLPClassifier(hidden_layer_sizes=(100,100),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(100,100,100),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(100,50,20),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "             MLPClassifier(hidden_layer_sizes=(200,100, 50, 25),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(200,200,200),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(300,150,75),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               )\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d39c976",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_mlp_downsampling = [MLPClassifier(hidden_layer_sizes=(25,),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "             MLPClassifier(hidden_layer_sizes=(25,25),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(25,25,25),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(25,15,10),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "             MLPClassifier(hidden_layer_sizes=(15,),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(15,15),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(15,15,15),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "             MLPClassifier(hidden_layer_sizes=(30,15, 5),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               ),\n",
    "            MLPClassifier(hidden_layer_sizes=(5,5,5),\n",
    "                solver=\"adam\",\n",
    "                activation=\"relu\",\n",
    "                learning_rate_init=0.002,\n",
    "                learning_rate=\"adaptive\",\n",
    "                max_iter=2000\n",
    "               )\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fe33849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(hidden_layer_sizes=(25,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(25, 25), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(25, 25, 25), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(25, 15, 10), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(15,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(15, 15), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(15, 15, 15), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(30, 15, 5), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(5, 5, 5), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n"
     ]
    }
   ],
   "source": [
    "# train models\n",
    "for model in models_mlp_downsampling:\n",
    "    model.fit(x_reduced_train, y_reduced_train)\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00d0cff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(hidden_layer_sizes=(50,), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(50, 50), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(50, 50, 50), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(50, 30, 10), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(100, 100), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(100, 100, 100), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(100, 50, 20), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(200, 100, 50, 25), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(200, 200, 200), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "MLPClassifier(hidden_layer_sizes=(300, 150, 75), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n"
     ]
    }
   ],
   "source": [
    "# train models\n",
    "for model in models_mlp:\n",
    "    model.fit(x_reduced_train, y_reduced_train)\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5587e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_2 = {i: None for i in models_mlp}\n",
    "for model, model_str in zip(models_mlp, predictions_2):\n",
    "    predictions_2[model_str] = model.predict(x_reduced_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5df55650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=20, max_leaf_nodes=162,\n",
      "                       min_impurity_decrease=6e-05, min_samples_leaf=20,\n",
      "                       random_state=10)\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=20, max_leaf_nodes=162,\n",
      "                       min_impurity_decrease=6e-05, min_samples_leaf=20,\n",
      "                       n_estimators=75, random_state=10)\n",
      "MLPClassifier(hidden_layer_sizes=(15, 30, 60), learning_rate='adaptive',\n",
      "              learning_rate_init=0.002, max_iter=2000)\n",
      "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced',\n",
      "                                                         max_depth=11,\n",
      "                                                         max_leaf_nodes=162,\n",
      "                                                         min_impurity_decrease=6e-05,\n",
      "                                                         min_samples_leaf=20,\n",
      "                                                         random_state=10),\n",
      "                   learning_rate=0.3, n_estimators=3300)\n",
      "GradientBoostingClassifier(learning_rate=0.05, n_estimators=3200)\n"
     ]
    }
   ],
   "source": [
    "# train models\n",
    "for model in models_reduced:\n",
    "    model.fit(x_reduced_train, y_reduced_train)\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "83c7ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_2 = {i: None for i in models_reduced}\n",
    "for model, model_str in zip(models_reduced, predictions_2):\n",
    "    predictions_2[model_str] = model.predict(x_reduced_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cd1f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predictions_2 = {i: None for i in models_mlp_downsampling}\n",
    "for model, model_str in zip(models_mlp_downsampling, predictions_2):\n",
    "    predictions_2[model_str] = model.predict(x_reduced_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "905ce850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy [%]</th>\n",
       "      <th>Precision [%]</th>\n",
       "      <th>Recall [%]</th>\n",
       "      <th>F1_score [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>87.3</td>\n",
       "      <td>75.7</td>\n",
       "      <td>93.5</td>\n",
       "      <td>83.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>99.9</td>\n",
       "      <td>99.9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>99.8</td>\n",
       "      <td>99.6</td>\n",
       "      <td>99.8</td>\n",
       "      <td>99.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultiLayerPercepton</td>\n",
       "      <td>96.8</td>\n",
       "      <td>92.9</td>\n",
       "      <td>98.3</td>\n",
       "      <td>95.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy [%]  Precision [%]  Recall [%]  F1_score [%]\n",
       "0           NaiveBayes          87.3           75.7        93.5          83.6\n",
       "1         DecisionTree          99.9           99.9       100.0          99.9\n",
       "2         RandomForest          99.8           99.6        99.8          99.7\n",
       "3  MultiLayerPercepton          96.8           92.9        98.3          95.5\n",
       "4             AdaBoost         100.0          100.0       100.0         100.0\n",
       "5        GradientBoost         100.0          100.0       100.0         100.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "# fpr_list = []\n",
    "for model, model_str in zip(models_reduced, predictions_2):\n",
    "    accuracy = accuracy_score(y_reduced_test, predictions_2[model_str])\n",
    "    precision = precision_score(y_reduced_test, predictions_2[model_str], average='binary')\n",
    "    recall = recall_score(y_reduced_test, predictions_2[model_str], average='binary')\n",
    "    f1_ = f1_score(y_reduced_test, predictions_2[model_str], average='binary')\n",
    "    \n",
    "    accuracy_list.append(round(accuracy, 3) * 100)\n",
    "    precision_list.append(round(precision,3) * 100)\n",
    "    recall_list.append(round(recall,3) * 100)\n",
    "    f1_list.append(round(f1_,3) * 100)\n",
    "\n",
    "# accuracy_list[3] = 83.9\n",
    "# precision_list[3] = 82.4\n",
    "\n",
    "# accuracy_list.append(86.6)\n",
    "# accuracy_list.append(86.6)\n",
    "# precision_list.append(81.3)\n",
    "# recall_list.append(98.5)\n",
    "# f1_list.append(89.1)\n",
    "# precision_list.append(78.2)\n",
    "# recall_list.append(99.2)\n",
    "# f1_list.append(87.5)\n",
    "\n",
    "results = {'Model': ['NaiveBayes', 'DecisionTree', 'RandomForest', 'MultiLayerPercepton', 'AdaBoost', 'GradientBoost'],\n",
    "           'Accuracy [%]': accuracy_list,\n",
    "           'Precision [%]': precision_list,\n",
    "           'Recall [%]': recall_list,\n",
    "           'F1_score [%]': f1_list,\n",
    "#            'FPR_score [%]': fpr_list\n",
    "          }\n",
    " \n",
    "# Convert the dictionary into DataFrame \n",
    "result_metrics = pd.DataFrame(results)\n",
    "result_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0d42057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy [%]</th>\n",
       "      <th>Precision [%]</th>\n",
       "      <th>Recall [%]</th>\n",
       "      <th>F1_score [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(50,), learni...</td>\n",
       "      <td>95.8</td>\n",
       "      <td>90.8</td>\n",
       "      <td>98.0</td>\n",
       "      <td>94.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(50, 50), lea...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>93.4</td>\n",
       "      <td>98.4</td>\n",
       "      <td>95.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(50, 50, 50),...</td>\n",
       "      <td>97.1</td>\n",
       "      <td>93.8</td>\n",
       "      <td>98.2</td>\n",
       "      <td>95.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(50, 30, 10),...</td>\n",
       "      <td>92.1</td>\n",
       "      <td>82.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>89.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(100, 100), l...</td>\n",
       "      <td>96.9</td>\n",
       "      <td>93.2</td>\n",
       "      <td>98.2</td>\n",
       "      <td>95.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(100, 100, 10...</td>\n",
       "      <td>96.6</td>\n",
       "      <td>92.4</td>\n",
       "      <td>98.3</td>\n",
       "      <td>95.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(100, 50, 20)...</td>\n",
       "      <td>94.4</td>\n",
       "      <td>87.2</td>\n",
       "      <td>98.3</td>\n",
       "      <td>92.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(200, 100, 50...</td>\n",
       "      <td>96.3</td>\n",
       "      <td>91.6</td>\n",
       "      <td>98.3</td>\n",
       "      <td>94.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(200, 200, 20...</td>\n",
       "      <td>92.7</td>\n",
       "      <td>94.1</td>\n",
       "      <td>84.2</td>\n",
       "      <td>88.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(300, 150, 75...</td>\n",
       "      <td>92.5</td>\n",
       "      <td>94.3</td>\n",
       "      <td>83.4</td>\n",
       "      <td>88.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  Accuracy [%]  \\\n",
       "0  MLPClassifier(hidden_layer_sizes=(50,), learni...          95.8   \n",
       "1  MLPClassifier(hidden_layer_sizes=(50, 50), lea...          97.0   \n",
       "2  MLPClassifier(hidden_layer_sizes=(50, 50, 50),...          97.1   \n",
       "3  MLPClassifier(hidden_layer_sizes=(50, 30, 10),...          92.1   \n",
       "4  MLPClassifier(hidden_layer_sizes=(100, 100), l...          96.9   \n",
       "5  MLPClassifier(hidden_layer_sizes=(100, 100, 10...          96.6   \n",
       "6  MLPClassifier(hidden_layer_sizes=(100, 50, 20)...          94.4   \n",
       "7  MLPClassifier(hidden_layer_sizes=(200, 100, 50...          96.3   \n",
       "8  MLPClassifier(hidden_layer_sizes=(200, 200, 20...          92.7   \n",
       "9  MLPClassifier(hidden_layer_sizes=(300, 150, 75...          92.5   \n",
       "\n",
       "   Precision [%]  Recall [%]  F1_score [%]  \n",
       "0           90.8        98.0          94.3  \n",
       "1           93.4        98.4          95.8  \n",
       "2           93.8        98.2          95.9  \n",
       "3           82.0        99.0          89.7  \n",
       "4           93.2        98.2          95.7  \n",
       "5           92.4        98.3          95.3  \n",
       "6           87.2        98.3          92.4  \n",
       "7           91.6        98.3          94.8  \n",
       "8           94.1        84.2          88.9  \n",
       "9           94.3        83.4          88.5  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "# fpr_list = []\n",
    "for model, model_str in zip(models_mlp, predictions_2):\n",
    "    accuracy = accuracy_score(y_reduced_test, predictions_2[model_str])\n",
    "    precision = precision_score(y_reduced_test, predictions_2[model_str], average='binary')\n",
    "    recall = recall_score(y_reduced_test, predictions_2[model_str], average='binary')\n",
    "    f1_ = f1_score(y_reduced_test, predictions_2[model_str], average='binary')\n",
    "    \n",
    "    accuracy_list.append(round(accuracy, 3) * 100)\n",
    "    precision_list.append(round(precision,3) * 100)\n",
    "    recall_list.append(round(recall,3) * 100)\n",
    "    f1_list.append(round(f1_,3) * 100)\n",
    "\n",
    "# accuracy_list[3] = 83.9\n",
    "# precision_list[3] = 82.4\n",
    "\n",
    "# accuracy_list.append(86.6)\n",
    "# accuracy_list.append(86.6)\n",
    "# precision_list.append(81.3)\n",
    "# recall_list.append(98.5)\n",
    "# f1_list.append(89.1)\n",
    "# precision_list.append(78.2)\n",
    "# recall_list.append(99.2)\n",
    "# f1_list.append(87.5)\n",
    "\n",
    "results = {'Model': models_mlp,\n",
    "           'Accuracy [%]': accuracy_list,\n",
    "           'Precision [%]': precision_list,\n",
    "           'Recall [%]': recall_list,\n",
    "           'F1_score [%]': f1_list,\n",
    "#            'FPR_score [%]': fpr_list\n",
    "          }\n",
    " \n",
    "# Convert the dictionary into DataFrame \n",
    "result_metrics = pd.DataFrame(results)\n",
    "result_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9a9ae53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy [%]</th>\n",
       "      <th>Precision [%]</th>\n",
       "      <th>Recall [%]</th>\n",
       "      <th>F1_score [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(25,), learni...</td>\n",
       "      <td>95.7</td>\n",
       "      <td>90.3</td>\n",
       "      <td>98.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(25, 25), lea...</td>\n",
       "      <td>96.9</td>\n",
       "      <td>93.3</td>\n",
       "      <td>98.3</td>\n",
       "      <td>95.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(25, 25, 25),...</td>\n",
       "      <td>96.8</td>\n",
       "      <td>93.1</td>\n",
       "      <td>98.1</td>\n",
       "      <td>95.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(25, 15, 10),...</td>\n",
       "      <td>96.9</td>\n",
       "      <td>93.2</td>\n",
       "      <td>98.3</td>\n",
       "      <td>95.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(15,), learni...</td>\n",
       "      <td>93.7</td>\n",
       "      <td>94.3</td>\n",
       "      <td>87.1</td>\n",
       "      <td>90.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(15, 15), lea...</td>\n",
       "      <td>96.6</td>\n",
       "      <td>97.1</td>\n",
       "      <td>93.1</td>\n",
       "      <td>95.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(15, 15, 15),...</td>\n",
       "      <td>97.3</td>\n",
       "      <td>96.8</td>\n",
       "      <td>95.3</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(30, 15, 5), ...</td>\n",
       "      <td>96.8</td>\n",
       "      <td>92.9</td>\n",
       "      <td>98.3</td>\n",
       "      <td>95.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MLPClassifier(hidden_layer_sizes=(5, 5, 5), le...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>75.2</td>\n",
       "      <td>93.5</td>\n",
       "      <td>83.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  Accuracy [%]  \\\n",
       "0  MLPClassifier(hidden_layer_sizes=(25,), learni...          95.7   \n",
       "1  MLPClassifier(hidden_layer_sizes=(25, 25), lea...          96.9   \n",
       "2  MLPClassifier(hidden_layer_sizes=(25, 25, 25),...          96.8   \n",
       "3  MLPClassifier(hidden_layer_sizes=(25, 15, 10),...          96.9   \n",
       "4  MLPClassifier(hidden_layer_sizes=(15,), learni...          93.7   \n",
       "5  MLPClassifier(hidden_layer_sizes=(15, 15), lea...          96.6   \n",
       "6  MLPClassifier(hidden_layer_sizes=(15, 15, 15),...          97.3   \n",
       "7  MLPClassifier(hidden_layer_sizes=(30, 15, 5), ...          96.8   \n",
       "8  MLPClassifier(hidden_layer_sizes=(5, 5, 5), le...          87.0   \n",
       "\n",
       "   Precision [%]  Recall [%]  F1_score [%]  \n",
       "0           90.3        98.0          94.0  \n",
       "1           93.3        98.3          95.7  \n",
       "2           93.1        98.1          95.6  \n",
       "3           93.2        98.3          95.7  \n",
       "4           94.3        87.1          90.6  \n",
       "5           97.1        93.1          95.1  \n",
       "6           96.8        95.3          96.0  \n",
       "7           92.9        98.3          95.5  \n",
       "8           75.2        93.5          83.3  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "# fpr_list = []\n",
    "for model, model_str in zip(models_mlp_downsampling, predictions_2):\n",
    "    accuracy = accuracy_score(y_reduced_test, predictions_2[model_str])\n",
    "    precision = precision_score(y_reduced_test, predictions_2[model_str], average='binary')\n",
    "    recall = recall_score(y_reduced_test, predictions_2[model_str], average='binary')\n",
    "    f1_ = f1_score(y_reduced_test, predictions_2[model_str], average='binary')\n",
    "    \n",
    "    accuracy_list.append(round(accuracy, 3) * 100)\n",
    "    precision_list.append(round(precision,3) * 100)\n",
    "    recall_list.append(round(recall,3) * 100)\n",
    "    f1_list.append(round(f1_,3) * 100)\n",
    "\n",
    "# accuracy_list[3] = 83.9\n",
    "# precision_list[3] = 82.4\n",
    "\n",
    "# accuracy_list.append(86.6)\n",
    "# accuracy_list.append(86.6)\n",
    "# precision_list.append(81.3)\n",
    "# recall_list.append(98.5)\n",
    "# f1_list.append(89.1)\n",
    "# precision_list.append(78.2)\n",
    "# recall_list.append(99.2)\n",
    "# f1_list.append(87.5)\n",
    "\n",
    "results = {'Model': models_mlp_downsampling,\n",
    "           'Accuracy [%]': accuracy_list,\n",
    "           'Precision [%]': precision_list,\n",
    "           'Recall [%]': recall_list,\n",
    "           'F1_score [%]': f1_list,\n",
    "#            'FPR_score [%]': fpr_list\n",
    "          }\n",
    " \n",
    "# Convert the dictionary into DataFrame \n",
    "result_metrics = pd.DataFrame(results)\n",
    "result_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e85489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "607fcf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 18:55:56.176668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-07 18:55:56.177032: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-07 18:55:56.177101: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-07 18:55:56.177160: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-07 18:55:56.197804: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-07 18:55:56.197868: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-07 18:55:56.197926: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-06-07 18:55:56.197935: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-06-07 18:55:56.198773: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(LSTM(300, activation=\"tanh\", return_sequences = True, input_shape = (10, 1)))\n",
    "model2.add(Dropout(0.4))\n",
    "\n",
    "model2.add(LSTM(200, activation=\"tanh\", return_sequences = True))\n",
    "model2.add(Dropout(0.4))\n",
    "\n",
    "model2.add(LSTM(100, activation=\"tanh\", return_sequences = True))\n",
    "model2.add(Dropout(0.4))\n",
    "\n",
    "model2.add(LSTM(80, activation=\"tanh\"))\n",
    "model2.add(Dropout(0.4))\n",
    "\n",
    "model2.add(Dense(1))\n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "400cceaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5764/5764 [==============================] - 320s 55ms/step - loss: 0.2869 - accuracy: 0.8644 - val_loss: 0.2589 - val_accuracy: 0.8711\n",
      "Epoch 2/20\n",
      "5764/5764 [==============================] - 319s 55ms/step - loss: 0.2633 - accuracy: 0.8713 - val_loss: 0.2600 - val_accuracy: 0.9015\n",
      "Epoch 3/20\n",
      "5764/5764 [==============================] - 323s 56ms/step - loss: 0.2525 - accuracy: 0.8734 - val_loss: 0.1842 - val_accuracy: 0.8858\n",
      "Epoch 4/20\n",
      "5764/5764 [==============================] - 332s 58ms/step - loss: 0.2428 - accuracy: 0.8739 - val_loss: 0.1838 - val_accuracy: 0.9013\n",
      "Epoch 5/20\n",
      "5764/5764 [==============================] - 315s 55ms/step - loss: 0.2147 - accuracy: 0.8910 - val_loss: 0.1563 - val_accuracy: 0.9220\n",
      "Epoch 6/20\n",
      "5764/5764 [==============================] - 315s 55ms/step - loss: 0.1869 - accuracy: 0.9074 - val_loss: 0.3346 - val_accuracy: 0.8716\n",
      "Epoch 7/20\n",
      "5764/5764 [==============================] - 317s 55ms/step - loss: 0.2280 - accuracy: 0.8867 - val_loss: 0.2700 - val_accuracy: 0.8715\n",
      "Epoch 8/20\n",
      "5764/5764 [==============================] - 315s 55ms/step - loss: 0.2111 - accuracy: 0.8954 - val_loss: 0.2492 - val_accuracy: 0.8728\n",
      "Epoch 9/20\n",
      "5764/5764 [==============================] - 315s 55ms/step - loss: 0.2251 - accuracy: 0.8892 - val_loss: 0.3100 - val_accuracy: 0.8688\n",
      "Epoch 10/20\n",
      "5764/5764 [==============================] - 322s 56ms/step - loss: 0.2752 - accuracy: 0.8744 - val_loss: 0.3186 - val_accuracy: 0.8688\n",
      "Epoch 11/20\n",
      "5764/5764 [==============================] - 317s 55ms/step - loss: 0.2594 - accuracy: 0.8837 - val_loss: 0.3202 - val_accuracy: 0.8688\n",
      "Epoch 12/20\n",
      "5764/5764 [==============================] - 322s 56ms/step - loss: 0.2815 - accuracy: 0.8791 - val_loss: 0.2003 - val_accuracy: 0.8887\n",
      "Epoch 13/20\n",
      "5764/5764 [==============================] - 318s 55ms/step - loss: 0.2299 - accuracy: 0.8911 - val_loss: 0.1849 - val_accuracy: 0.9087\n",
      "Epoch 14/20\n",
      "5764/5764 [==============================] - 323s 56ms/step - loss: 0.2213 - accuracy: 0.8954 - val_loss: 0.2998 - val_accuracy: 0.8715\n",
      "Epoch 15/20\n",
      "5764/5764 [==============================] - 319s 55ms/step - loss: 0.2187 - accuracy: 0.8994 - val_loss: 0.1660 - val_accuracy: 0.9220\n",
      "Epoch 16/20\n",
      "5764/5764 [==============================] - 319s 55ms/step - loss: 0.2226 - accuracy: 0.8949 - val_loss: 0.1661 - val_accuracy: 0.9220\n",
      "Epoch 17/20\n",
      "5764/5764 [==============================] - 324s 56ms/step - loss: 0.2159 - accuracy: 0.8996 - val_loss: 0.1720 - val_accuracy: 0.9220\n",
      "Epoch 18/20\n",
      "5764/5764 [==============================] - 340s 59ms/step - loss: 0.2071 - accuracy: 0.9042 - val_loss: 0.2981 - val_accuracy: 0.8715\n",
      "Epoch 19/20\n",
      "5764/5764 [==============================] - 344s 60ms/step - loss: 0.2284 - accuracy: 0.8890 - val_loss: 0.2173 - val_accuracy: 0.8860\n",
      "Epoch 20/20\n",
      "5764/5764 [==============================] - 338s 59ms/step - loss: 0.2199 - accuracy: 0.8931 - val_loss: 0.2281 - val_accuracy: 0.8758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3fcb809fd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_reduced_train, y_reduced_train, batch_size=64, \n",
    "          epochs=20, validation_data=(x_reduced_test, y_reduced_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "080a43a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8757713455302628 0.7533423279774316 0.9563998754282155 0.8428130360205832\n"
     ]
    }
   ],
   "source": [
    "prediction2 = model2.predict(x_reduced_test)\n",
    "prediction2 = prediction2.flatten()\n",
    "prediction2 = [int(round(i,0)) for i in prediction2]\n",
    "\n",
    "accuracy = accuracy_score(y_reduced_test, prediction2)\n",
    "precision = precision_score(y_reduced_test, prediction2, average='binary')\n",
    "recall = recall_score(y_reduced_test, prediction2, average='binary')\n",
    "f1_ = f1_score(y_reduced_test, prediction2, average='binary')\n",
    "\n",
    "print(accuracy, precision, recall, f1_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0df431ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GRU2 = Sequential()\n",
    "\n",
    "model_GRU2.add(GRU(300, activation=\"tanh\", return_sequences = True, input_shape = (10, 1)))\n",
    "model_GRU2.add(Dropout(0.4))\n",
    "\n",
    "model_GRU2.add(GRU(200, activation=\"tanh\", return_sequences = True))\n",
    "model_GRU2.add(Dropout(0.4))\n",
    "\n",
    "model_GRU2.add(GRU(100, activation=\"tanh\", return_sequences = True))\n",
    "model_GRU2.add(Dropout(0.4))\n",
    "\n",
    "model_GRU2.add(GRU(80, activation=\"tanh\"))\n",
    "model_GRU2.add(Dropout(0.4))\n",
    "\n",
    "model_GRU2.add(Dense(1))\n",
    "model_GRU2.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model_GRU2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4cbb1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5764/5764 [==============================] - 278s 47ms/step - loss: 0.2723 - accuracy: 0.8735 - val_loss: 0.1480 - val_accuracy: 0.9571\n",
      "Epoch 2/20\n",
      "5764/5764 [==============================] - 274s 47ms/step - loss: 0.1601 - accuracy: 0.9328 - val_loss: 0.0948 - val_accuracy: 0.9670\n",
      "Epoch 3/20\n",
      "5764/5764 [==============================] - 278s 48ms/step - loss: 0.1256 - accuracy: 0.9491 - val_loss: 0.1671 - val_accuracy: 0.9411\n",
      "Epoch 4/20\n",
      "5764/5764 [==============================] - 303s 53ms/step - loss: 0.1628 - accuracy: 0.9384 - val_loss: 0.1168 - val_accuracy: 0.9589\n",
      "Epoch 5/20\n",
      "5764/5764 [==============================] - 302s 52ms/step - loss: 0.1575 - accuracy: 0.9385 - val_loss: 0.3414 - val_accuracy: 0.8685\n",
      "Epoch 6/20\n",
      "5764/5764 [==============================] - 302s 52ms/step - loss: 0.2393 - accuracy: 0.8849 - val_loss: 0.2939 - val_accuracy: 0.8728\n",
      "Epoch 7/20\n",
      "5764/5764 [==============================] - 292s 51ms/step - loss: 0.2606 - accuracy: 0.8775 - val_loss: 0.2069 - val_accuracy: 0.8874\n",
      "Epoch 8/20\n",
      "5764/5764 [==============================] - 310s 54ms/step - loss: 0.2560 - accuracy: 0.8837 - val_loss: 0.1682 - val_accuracy: 0.9280\n",
      "Epoch 9/20\n",
      "5764/5764 [==============================] - 308s 53ms/step - loss: 0.1992 - accuracy: 0.9054 - val_loss: 0.1730 - val_accuracy: 0.9059\n",
      "Epoch 10/20\n",
      "5764/5764 [==============================] - 307s 53ms/step - loss: 0.2170 - accuracy: 0.8919 - val_loss: 0.2884 - val_accuracy: 0.8688\n",
      "Epoch 11/20\n",
      "5764/5764 [==============================] - 322s 56ms/step - loss: 0.2259 - accuracy: 0.8897 - val_loss: 0.2153 - val_accuracy: 0.8860\n",
      "Epoch 12/20\n",
      "5764/5764 [==============================] - 339s 59ms/step - loss: 0.2947 - accuracy: 0.8624 - val_loss: 0.2369 - val_accuracy: 0.8989\n",
      "Epoch 13/20\n",
      "5764/5764 [==============================] - 309s 54ms/step - loss: 0.2164 - accuracy: 0.8946 - val_loss: 0.1656 - val_accuracy: 0.9220\n",
      "Epoch 14/20\n",
      "5764/5764 [==============================] - 320s 55ms/step - loss: 0.2067 - accuracy: 0.8963 - val_loss: 0.1932 - val_accuracy: 0.8924\n",
      "Epoch 15/20\n",
      "5764/5764 [==============================] - 320s 56ms/step - loss: 0.2058 - accuracy: 0.9040 - val_loss: 0.2581 - val_accuracy: 0.8742\n",
      "Epoch 16/20\n",
      "5764/5764 [==============================] - 315s 55ms/step - loss: 0.2139 - accuracy: 0.8920 - val_loss: 0.1584 - val_accuracy: 0.9220\n",
      "Epoch 17/20\n",
      "5764/5764 [==============================] - 311s 54ms/step - loss: 0.2138 - accuracy: 0.8912 - val_loss: 0.3289 - val_accuracy: 0.8662\n",
      "Epoch 18/20\n",
      "5764/5764 [==============================] - 312s 54ms/step - loss: 0.2322 - accuracy: 0.8847 - val_loss: 0.1870 - val_accuracy: 0.8874\n",
      "Epoch 19/20\n",
      "5764/5764 [==============================] - 322s 56ms/step - loss: 0.2297 - accuracy: 0.8857 - val_loss: 0.2085 - val_accuracy: 0.8861\n",
      "Epoch 20/20\n",
      "5764/5764 [==============================] - 303s 53ms/step - loss: 0.2504 - accuracy: 0.8793 - val_loss: 0.2056 - val_accuracy: 0.8874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3f984a7fd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_GRU2.fit(x_reduced_train, y_reduced_train, batch_size=64, \n",
    "          epochs=20, validation_data=(x_reduced_test, y_reduced_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a469a80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8873971087420968 0.7596624997012215 0.9897851136717534 0.859588624284961\n"
     ]
    }
   ],
   "source": [
    "prediction_gru2 = model_GRU2.predict(x_reduced_test)\n",
    "prediction_gru2 = prediction_gru2.flatten()\n",
    "prediction_gru2 = [int(round(i,0)) for i in prediction_gru2]\n",
    "\n",
    "accuracy = accuracy_score(y_reduced_test, prediction_gru2)\n",
    "precision = precision_score(y_reduced_test, prediction_gru2, average='binary')\n",
    "recall = recall_score(y_reduced_test, prediction_gru2, average='binary')\n",
    "f1_ = f1_score(y_reduced_test, prediction_gru2, average='binary')\n",
    "\n",
    "print(accuracy, precision, recall, f1_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3236ec4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
